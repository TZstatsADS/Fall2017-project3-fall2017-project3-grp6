test.lbp = lbpdata[test.index,]
test.x.lbp = test.lbp[,-1]
train.lbp = lbpdata[-test.index,]
X = train.lbp[,-1]
y = train.lbp[,1]
bp.model=train.bp(train.lbp)
bp.model=train.bp(train.lbp)
bp.pre=test.bp(bp.model,test.x.lbp)
bp.pre=test.bp(bp.model,test.x.lbp)
table(bp.pre,test.lbp$y)
rf.model <- train.rf(train.lbp)
rf.model <- train.rf(train.lbp)
rf.pre=test.rf(rf.model,test.x.lbp)
table(rf.pre,test.lbp$y)
svm.model <- train.svm(train.lbp)
svm.model <- train.svm(train.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
table(svm.pre,test.lbp$y)
log.model <- train.log(train.lbp)
log.pre=test.log(log.model,test.x.lbp)
table(log.pre, test.lbp$y)
xgboost.model = train.xgboost(train.lbp)
xgboost.model = train.xgboost(train.lbp)
xgboost.pre = test.xgboost(xgboost.model,test.x.lbp)
table(xgboost.pre, test.lbp$y)
hogdata = data.frame(cbind(label,hog.feature[,-1]))
colnames(hogdata)[2] = "y"
hogdata = hogdata[,-1]
test.hog = hogdata[test.index,]
test.x.hog = test.hog[,-1]
train.hog = hogdata[-test.index,]
bp.model=train.bp(train.hog)
bp.pre=test.bp(bp.model,test.x.hog)
table(bp.pre,test.hog$y)
rf.model <- train.rf(train.hog)
rf.model <- train.rf(train.hog)
rf.pre=test.rf(rf.model,test.x.hog)
table(rf.pre,test.hog$y)
svm.model <- train.svm(train.hog)
svm.model <- train.svm(train.hog)
svm.pre=test.svm(svm.model,test.x.hog)
svm.pre=test.svm(svm.model,test.x.hog)
table(svm.pre,test.hog$y)
log.model <- train.log(train.hog)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
xgboost.model = train.xgboost(train.hog)
xgboost.model = train.xgboost(train.hog)
xgboost.pre = test.xgboost(xgboost.model,test.x.hog)
table(xgboost.pre, test.hog$y)
source("../lib/cross_validation.R")
cv.error=cv.function(train, 5)
a=system.time(baseline <- train.baseline(all))
b=system.time(gbm <- train.baseline(new.data))
c=system.time(bp <- train.bp(new.data))
e=system.time(svm <- train.svm(new.data))
cv.error=cv.function(train, 5)
n <- nrow(data)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error.baseline.sift <- rep(NA, K)
cv.error.baseline <- rep(NA, K)
cv.error.BP <- rep(NA, K)
cv.error.rf <- rep(NA, K)
cv.error.svm <- rep(NA, K)
cv.error.log <- rep(NA, K)
n <- nrow(data)
n.fold <- floor(n/K)
#cv.function <- function(data, K){
data = train
#cv.function <- function(data, K){
data = train.lbp
K=5
n <- nrow(data)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error.baseline.sift <- rep(NA, K)
cv.error.baseline <- rep(NA, K)
cv.error.BP <- rep(NA, K)
cv.error.rf <- rep(NA, K)
cv.error.svm <- rep(NA, K)
cv.error.log <- rep(NA, K)
cv.error.vote <- rep(NA, K)
for (i in 1:K){
train.data <- data[s != i,]
test.data <- data[s == i,]
fit.baseline.sift <- train.baseline(train.sift)
pred.bs.sift<- test.baseline(fit.baseline.sift, test.x.sift)
cv.error.baseline.sift[i] <- mean(pred.bs.sift != test.sift$y)
fit.baseline <- train.baseline(train.data)
pred.baseline <- test.baseline(fit.baseline, test.data)
cv.error.baseline[i] <- mean(pred.baseline != test.data$y)
fit.BP <- train.bp(train.data)
pred.BP <- test.bp(fit.BP, test.data)
cv.error.BP[i] <- mean(pred.BP != test.data$y)
fit.rf <- train.rf(train.data)
pred.rf <- test.rf(fit.rf, test.data)
cv.error.rf[i] <- mean(pred.rf != test.data$y)
fit.svm <- train.svm(train.data)
pred.svm <- test.svm(fit.svm, test.data)
cv.error.svm[i] <- mean(pred.svm != test.data$y)
fit.log <- train.log(train.data)
pred.log <- test.log(fit.log, test.data)
cv.error.log[i] <- mean(pred.log != test.data$y)
pre=(as.numeric(as.character(pred.BP))+as.numeric(as.character(pred.log))+as.numeric(as.character(pred.svm)))
pre=ifelse(pre>=2,1,0)
cv.error.vote[i] <- mean(pre != test.data$y)
}
for (i in 1:K){
train.data <- data[s != i,]
test.data <- data[s == i,]
fit.BP <- train.bp(train.data)
pred.BP <- test.bp(fit.BP, test.data)
cv.error.BP[i] <- mean(pred.BP != test.data$y)
fit.rf <- train.rf(train.data)
pred.rf <- test.rf(fit.rf, test.data)
cv.error.rf[i] <- mean(pred.rf != test.data$y)
fit.svm <- train.svm(train.data)
pred.svm <- test.svm(fit.svm, test.data)
cv.error.svm[i] <- mean(pred.svm != test.data$y)
fit.log <- train.log(train.data)
pred.log <- test.log(fit.log, test.data)
cv.error.log[i] <- mean(pred.log != test.data$y)
pre=(as.numeric(as.character(pred.BP))+as.numeric(as.character(pred.log))+as.numeric(as.character(pred.svm)))
pre=ifelse(pre>=2,1,0)
cv.error.vote[i] <- mean(pre != test.data$y)
}
cv.error<- data.frame(baseline = mean(cv.error.baseline.sift),
gbm = mean(cv.error.baseline) ,bp = mean(cv.error.BP),
rf = mean(cv.error.rf), svm = mean(cv.error.svm),
logistic= mean(cv.error.log),vote= mean(cv.error.vote))
cv.error
cv.error=cv.function(train, 5)
cv.error.hog = cv.function(train.hog,5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.function(train.lbp, 5)
cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
xgboost.model = train.xgboost(train.hog)
xgboost.model = train.xgboost(train.hog)
xgboost.pre = test.xgboost(xgboost.model,test.hog)
table(xgboost.pre, test.hog$y)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
View(cv.error.lbp)
View(cv.error.hog)
View(cv.error.lbp)
print (cv.error.lbp)
print(cv.error.hog)
print (cv.error.lbp)
c=system.time(bp <- train.bp(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
f=system.time(logistic <- train.log(lbpdata))
time=list(baseline=a,gbm=b,bp=c,rf=d,svm=e,logistic=f,vote=NA)
time=list(gbm=b,bp=c,rf=d,svm=e,logistic=f,vote=NA)
time=list(bp=c,rf=d,svm=e,logistic=f,vote=NA)
cv.error
time
cv.error.lbp
cv.error.hog
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
write(time,"time.csv")
time=list(bp=c,rf=d,svm=e,logistic=f,vote=NA)
write(time,"time.csv")
print(time)
View(hogdata)
View(hogdata)
g = system.time(xgboost = train.xgboost(lbpdata))
g = system.time(xgboost = train.xgboost(lbpdata))
View(lbpdata)
g = system.time(xgboost = train.xgboost(lbpdata))
g = system.time(xgboost <- train.xgboost(lbpdata))
time=list(bp=c,rf=d,svm=e,logistic=f,xgboost = g)
time
cv.error.lbp =cv.function(lbpdata,5)
cv.error.lbp =cv.function(lbpdata,5)
cv.error.hog = cv.function(hogdata,5)
print (cv.error.lbp)
print(cv.error.hog)
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
source("../lib/cross_validation.R")
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(lbpdata,5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(lbpdata,5)
cv.error.lbp =cv.function(lbpdata,5)
cv.error.hog = cv.function(hogdata,5)
source("../lib/cross_validation.R")
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
library("EBImage")
library("EBImage")
library("gbm")
library("EBImage")
library("gbm")
library("caret")
library("DMwR")
library("nnet")
library("randomForest")
library("DMwR")
library("nnet")
library("randomForest")
library("e1071")
library("data.table")
library("xgboost")
packages.used=c("gbm", "caret","DMwR" ,"nnet","randomForest","e1071","data.table","readr","xgboost")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
packages.used=c("gbm", "caret","DMwR" ,"nnet","randomForest","e1071","data.table","readr","xgboost")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
packages.used=c("gbm", "caret","DMwR" ,"nnet","randomForest","e1071","data.table","readr","xgboost")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
library("EBImage")
library("gbm")
library("caret")
library("DMwR")
library("nnet")
library("randomForest")
library("e1071")
library("data.table")
library("xgboost")
setwd("/Users/sijianxuan/Documents/Github/Fall2017-project3-fall2017-project3-grp6/doc")
setwd("/Users/sijianxuan/Documents/Github/Fall2017-project3-fall2017-project3-grp6/doc")
getwd()
sift.feature=read.csv("../data/sift_feature.csv", header = T)
sift.feature=read.csv("../data/sift_feature.csv", header = T)
lbp.feature=read.csv("../data/lbp_feature.csv", header = F)
hog.feature = read.csv("../data/hog_feature.csv")
label=read.csv("../data/trainlabel.csv")
sift_data=data.frame(cbind(label,sift.feature[,-1]))
test.index=sample(1:3000,500,replace=F)
colnames(sift_data)[2]="y"
sift_data = sift_data[,-1]
test.sift=sift_data[test.index,]
test.x.sift=test.sift[,-1]
train.sift=sift_data[-test.index,]
read.csv("../lib/err_cv_for_baseline.csv")
a=read.csv("../lib/err_cv_for_baseline.csv")
a
err_cv_for_baseline = read.csv("../lib/err_cv_for_baseline.csv")
source("../lib/train.r")
source("../lib/test.r")
lbpdata = data.frame(cbind(label,lbp.feature))
colnames(lbpdata)[2] = "y"
lbpdata = lbpdata[,-1]
test.lbp = lbpdata[test.index,]
test.x.lbp = test.lbp[,-1]
train.lbp = lbpdata[-test.index,]
source("../lib/train.r")
source("../lib/test.r")
lbpdata = data.frame(cbind(label,lbp.feature))
colnames(lbpdata)[2] = "y"
lbpdata = lbpdata[,-1]
test.lbp = lbpdata[test.index,]
test.x.lbp = test.lbp[,-1]
train.lbp = lbpdata[-test.index,]
err_cv_for_GBM+LBP.csv = read.csv("../lib/err_cv_for_GBM+LBP.csv")
err_cv_for_GBM+LBP.csv = read.csv("../lib/err_cv_for_GBM+LBP.csv")
err_cv_for_GBM+LBP.csv = read.csv("../lib/err_cv_for_GBM+LBP.csv")
err_cv_for_GBM_LBP = read.csv("../lib/err_cv_for_GBM+LBP.csv")
print(err_cv_for_GBM+LBP.csv)
print(err_cv_for_GBM_LBP)
bp.model=train.bp(train.lbp)
bp.pre=test.bp(bp.model,test.x.lbp)
table(bp.pre,test.lbp$y)
rf.model <- train.rf(train.lbp)
rf.model <- train.rf(train.lbp)
rf.pre=test.rf(rf.model,test.x.lbp)
table(rf.pre,test.lbp$y)
svm.model <- train.svm(train.lbp)
svm.model <- train.svm(train.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
table(svm.pre,test.lbp$y)
log.model <- train.log(train.lbp)
log.model <- train.log(train.lbp)
log.pre=test.log(log.model,test.x.lbp)
log.pre=test.log(log.model,test.x.lbp)
table(log.pre, test.lbp$y)
xgboost.model = train.xgboost(train.lbp)
xgboost.model = train.xgboost(train.lbp)
xgboost.pre = test.xgboost(xgboost.model,test.lbp)
table(xgboost.pre, test.lbp$y)
hogdata = data.frame(cbind(label,hog.feature[,-1]))
colnames(hogdata)[2] = "y"
hogdata = hogdata[,-1]
test.hog = hogdata[test.index,]
test.x.hog = test.hog[,-1]
train.hog = hogdata[-test.index,]
bp.model=train.bp(train.hog)
bp.pre=test.bp(bp.model,test.x.hog)
table(bp.pre,test.hog$y)
rf.model <- train.rf(train.hog)
rf.model <- train.rf(train.hog)
rf.pre=test.rf(rf.model,test.x.hog)
table(rf.pre,test.hog$y)
svm.model <- train.svm(train.hog)
svm.pre=test.svm(svm.model,test.x.hog)
table(svm.pre,test.hog$y)
###tune logistic regression model
glm.fit=multinom(y~., data=training,trace = F)
svm.model <- train.svm(train.hog)
svm.model <- train.svm(train.hog)
svm.pre=test.svm(svm.model,test.x.hog)
table(svm.pre,test.hog$y)
###tune logistic regression model
glm.fit=multinom(y~., data=train.hog,trace = F)
summary(glm.fit)
#Prediction
glm.pred<-predict(glm.fit, test.hog, type = "class")
mean(test.hog$y==glm.pred)  ##82%
###tune logistic regression model
glm.fit=multinom(y~., data=train.hog,trace = F)
#Prediction
glm.pred<-predict(glm.fit, test.hog, type = "class")
mean(test.hog$y==glm.pred)  ##82%
###tune logistic regression model
glm.fit=multinom(y~., data=train.hog,trace = F)
#Prediction
glm.pred<-predict(glm.fit, test.hog, type = "class")
mean(test.hog$y==glm.pred)  ##82%
#cv
cv.lr <- function(X.train, y.train,K){
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.accu.lr <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
glm=multinom(train.label~., data=train.data,maxit = 500,trace = F)
#Prediction
pred<-predict(glm, test.data, type = "class")
cv.accu.lr[i] <- mean(pred == test.label)
}
print(mean(cv.accu.lr))
}
cv.lr(training[,-1],training[,1], 5)
cv.lr(train.hog[,-1],train.hog[,1], 5)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
cv.lr(train.hog[,-1],train.hog[,1], 5)
glm.fit=multinom(y~., data=train.hog,trace = F)
#Prediction
glm.pred<-predict(glm.fit, test.hog, type = "class")
mean(test.hog$y==glm.pred)
#cv
cv.lr <- function(X.train, y.train,K){
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.accu.lr <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
glm=multinom(train.label~., data=train.data,maxit = 500,trace = F)
#Prediction
pred<-predict(glm, test.data, type = "class")
cv.accu.lr[i] <- mean(pred == test.label)
}
print(mean(cv.accu.lr))
}
cv.lr(train.hog[,-1],train.hog[,1], 5)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
trainnn<-as.matrix(training)
testtt<-as.matrix(testing)
trainnn<-as.matrix(training)
trainnn<-as.matrix(train.hog)
testtt<-as.matrix(test.hog)
dtrain=xgb.DMatrix(data=trainnn[,-1],label=trainnn[,1])
NROUNDS = c(500,1000)
ETA = c(0.3)
MAX_DEPTH = c(3,4,5,6)
cv.xgb <- function(X.train, y.train, K, NROUNDS, ETA, MAX_DEPTH){
for (nround in NROUNDS){
for (eta in ETA){
for (max_depth in MAX_DEPTH){
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.acc <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
param <- list("objective" = "multi:softmax",
"eval_metric" = "mlogloss",
"num_class" = 3, 'eta' = eta, 'max_depth' = max_depth)
dtrain=xgb.DMatrix(data=train.data,label=train.label)
bst <- xgb.train(data = dtrain,  param = param, nrounds = nround)
pred <- predict(bst, newdata = test.data)
cv.acc[i] <- mean(pred == test.label)
}
print(paste("------Mean 5-fold cv accuracy for nround=",nround,",eta=",eta,",max_depth=",max_depth,
"------",mean(cv.acc)))
key = c(nround,eta,max_depth)
CV_ERRORS[key] = mean(cv.acc)
}
}
}
}
CV_ERRORS = list()
cv.xgb(trainnn[,-1], trainnn[,1], 5, NROUNDS, ETA, MAX_DEPTH)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
result = cv.xgb(trainnn[,-1], trainnn[,1], 5, NROUNDS, ETA, MAX_DEPTH)
CV_ERRORS = list()
result = cv.xgb(trainnn[,-1], trainnn[,1], 5, NROUNDS, ETA, MAX_DEPTH)
result = cv.xgb(trainnn[,-1], trainnn[,1], 5, NROUNDS, ETA, MAX_DEPTH)
write.csv(result,"../lib/xgboost_model_tuning.csv")
result = cv.xgb(trainnn[,-1], trainnn[,1], 5, NROUNDS, ETA, MAX_DEPTH)
write.csv(result,"../lib/xgboost_model_tuning.csv")
write.csv(result,"../lib/xgboost_model_tuning.csv")
read.csv("../lib.xgboost_model_training.csv")
write.csv(result,"../lib/xgboost_model_tuning.csv")
write.csv(result,"../lib/xgboost_model_tuning.csv")
type(result)
mode(result)
print(result)
xgboost.model = train.xgboost(train.hog)
xgboost.model = train.xgboost(train.hog)
xgboost.pre = test.xgboost(xgboost.model,test.hog)
table(xgboost.pre, test.hog$y)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(lbpdata,5)
print(cv.error.lbp)
print(cv.error.hog)
cv.error.lbp = read.csv("../lib/cv.error.lbp")
cv.error.lbp = read.csv("../lib/cv.error.lbp.csv")
cv.error.hog = read.csv("../lib/cv.error.hog.csv")
print(cv.error.lbp)
print(cv.error.hog)
print(cv.error.lbp)
print(cv.error.hog)
sift.feature=read.csv("../data/sift_feature.csv", header = T)
#a=system.time(baseline <- train.baseline(sift_data))
#b=system.time(gbm <- train.baseline(lbpdata))
c=system.time(bp <- train.bp(lbpdata))
#a=system.time(baseline <- train.baseline(sift_data))
#b=system.time(gbm <- train.baseline(lbpdata))
c=system.time(bp <- train.bp(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
f=system.time(logistic <- train.log(lbpdata))
g = system.time(xgboost <- train.xgboost(lbpdata))
time=list(bp=c,rf=d,svm=e,logistic=f,xgboost = g)
time_lbp=list(bp=c,rf=d,svm=e,logistic=f,xgboost = g)
print(time_lbp)
c=system.time(bp <- train.bp(hogdata))
c=system.time(bp <- train.bp(hogdata))
d=system.time(rf <- train.rf(hogdata))
d=system.time(rf <- train.rf(hogdata))
e=system.time(svm <- train.svm(hogdata))
f=system.time(logistic <- train.log(hogdata))
g = system.time(xgboost <- train.xgboost(hogdata))
g = system.time(xgboost <- train.xgboost(hogdata))
time_hog=list(bp=c,rf=d,svm=e,logistic=f,xgboost = g)
print(time_lbp)
print(time_hog)
write.csv(time_lbp,"../output/time_lbp.csv")
print(time_lbp)
print(time_hog)
print(time_lbp)
print(time_hog)
print(cv.error.lbp)
print(cv.error.hog)
print(cv.error.hog)
print(cv.error.lbp)
print(cv.error.hog)
View(hogdata)
