<<<<<<< HEAD
feature <- function(img_dir, set_name, data_name="data", export=T){
### Construct process features for training/testing images
### Sample simple feature: Extract row average raw pixel values as features
### Input: a directory that contains images ready for processing
### Output: an .RData file contains processed features for the images
### load libraries
library("EBImage")
n_files <- length(list.files(img_dir))
### determine img dimensions
img0 <-  readImage(paste0(img_dir, "img", "_", data_name, "_", set_name, "_", 1, ".jpg"))
mat1 <- as.matrix(img0)
n_r <- nrow(img0)
### store vectorized pixel values of images
dat <- matrix(NA, n_files, n_r)
for(i in 1:n_files){
img <- readImage(paste0(img_dir,  "img", "_", data_name, "_", set_name, "_", i, ".jpg"))
dat[i,] <- rowMeans(img)
}
### output constructed features
if(export){
save(dat, file=paste0("../output/feature_", data_name, "_", set_name, ".RData"))
}
return(dat)
}
train <- function(dat_train, label_train, par=NULL){
### Train a Gradient Boosting Model (GBM) using processed features from training images
### Input:
###  -  processed features from images
###  -  class labels for training images
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
fit_gbm <- gbm.fit(x=dat_train, y=label_train,
n.trees=2000,
distribution="bernoulli",
interaction.depth=depth,
bag.fraction = 0.5,
verbose=FALSE)
best_iter <- gbm.perf(fit_gbm, method="OOB", plot.it = FALSE)
return(list(fit=fit_gbm, iter=best_iter))
}
test <- function(fit_train, dat_test){
### Fit the classfication model with testing data
### Input:
###  - the fitted classification model using training data
###  -  processed features from testing images
### Output: training model specification
### load libraries
library("gbm")
pred <- predict(fit_train$fit, newdata=dat_test,
n.trees=fit_train$iter, type="response")
return(as.numeric(pred> 0.5))
}
cv.function <- function(X.train, y.train, d, K){
n <- length(y.train)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data <- X.train[s != i,]
train.label <- y.train[s != i]
test.data <- X.train[s == i,]
test.label <- y.train[s == i]
par <- list(depth=d)
fit <- train(train.data, train.label, par)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error),sd(cv.error)))
}
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
setwd("./ads_spr2017_proj3")
setwd("~/Documents/GitHub/Fall2017-project3-fall2017-project3-grp6/doc")
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "label_train.txt", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "label_train.txt", sep=""),
header=F)
a = paste(experiment_dir, "label_train.txt"
)
a
a = paste(experiment_dir, "label_train.txt", sep="")
a
label_train <- read.table(paste(experiment_dir, "label_train.txt", sep=""),
header=F)
=======
setwd("./ads_spr2017_proj3")
setwd("~/Documents/GitHub/Fall2017-project3-fall2017-project3-grp6/doc")
>>>>>>> 370a4bdb1b3a8c3cd7cf20b627474d3aee7e3d55
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "label_train.csv", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "label_train.csv", sep=""),
header=F)
label_train <- read.table(paste(experiment_dir, "label_train.csv", sep=""),
header=F)
label_train <- as.numeric(unlist(label_train) == "9")
<<<<<<< HEAD
label_train <- read.table(paste(experiment_dir, "label_train.csv", sep=""),
header=F)
label_train <- as.numeric(unlist(label_train) == "9")
label_train <- read.table(paste(experiment_dir, "label_train.csv", sep=""),
header=F)
?read.table
=======
>>>>>>> 370a4bdb1b3a8c3cd7cf20b627474d3aee7e3d55
packages.used=c("gbm", "caret","DMwR" ,"nnet","randomForest","e1071","data.table","readr","xgboost")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
library("EBImage")
library("EBImage")
library("gbm")
library("caret")
library("DMwR")
library("nnet")
library("DMwR")
library("nnet")
library("randomForest")
library("e1071")
library("data.table")
library("xgboost")
setwd("/Users/sijianxuan/Documents/Github/Fall2017-project3-fall2017-project3-grp6/doc")
sift.feature=read.csv("../data/sift_feature.csv", header = T)
sift.feature=read.csv("../data/sift_feature.csv", header = T)
lbp.feature=read.csv("../data/lbp_feature.csv", header = F)
hog.feature = read.csv("../data/hog_feature.csv")
label=read.csv("../data/trainlabel.csv")
sift_data=data.frame(cbind(label,sift.feature[,-1]))
test.index=sample(1:3000,500,replace=F)
colnames(sift_data)[2]="y"
sift_data = sift_data[,-1]
test.sift=sift_data[test.index,]
test.x.sift=test.sift[,-1]
train.sift=sift_data[-test.index,]
source("../lib/train.r")
source("../lib/test.r")
lbpdata = data.frame(cbind(label,lbp.feature))
colnames(lbpdata)[2] = "y"
lbpdata = lbpdata[,-1]
test.lbp = lbpdata[test.index,]
test.x.lbp = test.lbp[,-1]
train.lbp = lbpdata[-test.index,]
X = train.lbp[,-1]
y = train.lbp[,1]
bp.model=train.bp(train.lbp)
bp.model=train.bp(train.lbp)
bp.pre=test.bp(bp.model,test.x.lbp)
bp.pre=test.bp(bp.model,test.x.lbp)
table(bp.pre,test.lbp$y)
rf.model <- train.rf(train.lbp)
rf.model <- train.rf(train.lbp)
rf.pre=test.rf(rf.model,test.x.lbp)
table(rf.pre,test.lbp$y)
svm.model <- train.svm(train.lbp)
svm.model <- train.svm(train.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
svm.pre=test.svm(svm.model,test.x.lbp)
table(svm.pre,test.lbp$y)
log.model <- train.log(train.lbp)
log.pre=test.log(log.model,test.x.lbp)
table(log.pre, test.lbp$y)
xgboost.model = train.xgboost(train.lbp)
xgboost.model = train.xgboost(train.lbp)
xgboost.pre = test.xgboost(xgboost.model,test.x.lbp)
table(xgboost.pre, test.lbp$y)
hogdata = data.frame(cbind(label,hog.feature[,-1]))
colnames(hogdata)[2] = "y"
hogdata = hogdata[,-1]
test.hog = hogdata[test.index,]
test.x.hog = test.hog[,-1]
train.hog = hogdata[-test.index,]
bp.model=train.bp(train.hog)
bp.pre=test.bp(bp.model,test.x.hog)
table(bp.pre,test.hog$y)
rf.model <- train.rf(train.hog)
rf.model <- train.rf(train.hog)
rf.pre=test.rf(rf.model,test.x.hog)
table(rf.pre,test.hog$y)
svm.model <- train.svm(train.hog)
svm.model <- train.svm(train.hog)
svm.pre=test.svm(svm.model,test.x.hog)
svm.pre=test.svm(svm.model,test.x.hog)
table(svm.pre,test.hog$y)
log.model <- train.log(train.hog)
log.model <- train.log(train.hog)
log.pre=test.log(log.model,test.x.hog)
log.pre=test.log(log.model,test.x.hog)
table(log.pre, test.hog$y)
xgboost.model = train.xgboost(train.hog)
xgboost.model = train.xgboost(train.hog)
xgboost.pre = test.xgboost(xgboost.model,test.x.hog)
table(xgboost.pre, test.hog$y)
source("../lib/cross_validation.R")
cv.error=cv.function(train, 5)
a=system.time(baseline <- train.baseline(all))
b=system.time(gbm <- train.baseline(new.data))
c=system.time(bp <- train.bp(new.data))
e=system.time(svm <- train.svm(new.data))
cv.error=cv.function(train, 5)
n <- nrow(data)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error.baseline.sift <- rep(NA, K)
cv.error.baseline <- rep(NA, K)
cv.error.BP <- rep(NA, K)
cv.error.rf <- rep(NA, K)
cv.error.svm <- rep(NA, K)
cv.error.log <- rep(NA, K)
n <- nrow(data)
n.fold <- floor(n/K)
#cv.function <- function(data, K){
data = train
#cv.function <- function(data, K){
data = train.lbp
K=5
n <- nrow(data)
n.fold <- floor(n/K)
s <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error.baseline.sift <- rep(NA, K)
cv.error.baseline <- rep(NA, K)
cv.error.BP <- rep(NA, K)
cv.error.rf <- rep(NA, K)
cv.error.svm <- rep(NA, K)
cv.error.log <- rep(NA, K)
cv.error.vote <- rep(NA, K)
for (i in 1:K){
train.data <- data[s != i,]
test.data <- data[s == i,]
fit.baseline.sift <- train.baseline(train.sift)
pred.bs.sift<- test.baseline(fit.baseline.sift, test.x.sift)
cv.error.baseline.sift[i] <- mean(pred.bs.sift != test.sift$y)
fit.baseline <- train.baseline(train.data)
pred.baseline <- test.baseline(fit.baseline, test.data)
cv.error.baseline[i] <- mean(pred.baseline != test.data$y)
fit.BP <- train.bp(train.data)
pred.BP <- test.bp(fit.BP, test.data)
cv.error.BP[i] <- mean(pred.BP != test.data$y)
fit.rf <- train.rf(train.data)
pred.rf <- test.rf(fit.rf, test.data)
cv.error.rf[i] <- mean(pred.rf != test.data$y)
fit.svm <- train.svm(train.data)
pred.svm <- test.svm(fit.svm, test.data)
cv.error.svm[i] <- mean(pred.svm != test.data$y)
fit.log <- train.log(train.data)
pred.log <- test.log(fit.log, test.data)
cv.error.log[i] <- mean(pred.log != test.data$y)
pre=(as.numeric(as.character(pred.BP))+as.numeric(as.character(pred.log))+as.numeric(as.character(pred.svm)))
pre=ifelse(pre>=2,1,0)
cv.error.vote[i] <- mean(pre != test.data$y)
}
for (i in 1:K){
train.data <- data[s != i,]
test.data <- data[s == i,]
fit.BP <- train.bp(train.data)
pred.BP <- test.bp(fit.BP, test.data)
cv.error.BP[i] <- mean(pred.BP != test.data$y)
fit.rf <- train.rf(train.data)
pred.rf <- test.rf(fit.rf, test.data)
cv.error.rf[i] <- mean(pred.rf != test.data$y)
fit.svm <- train.svm(train.data)
pred.svm <- test.svm(fit.svm, test.data)
cv.error.svm[i] <- mean(pred.svm != test.data$y)
fit.log <- train.log(train.data)
pred.log <- test.log(fit.log, test.data)
cv.error.log[i] <- mean(pred.log != test.data$y)
pre=(as.numeric(as.character(pred.BP))+as.numeric(as.character(pred.log))+as.numeric(as.character(pred.svm)))
pre=ifelse(pre>=2,1,0)
cv.error.vote[i] <- mean(pre != test.data$y)
}
cv.error<- data.frame(baseline = mean(cv.error.baseline.sift),
gbm = mean(cv.error.baseline) ,bp = mean(cv.error.BP),
rf = mean(cv.error.rf), svm = mean(cv.error.svm),
logistic= mean(cv.error.log),vote= mean(cv.error.vote))
cv.error
cv.error=cv.function(train, 5)
cv.error.hog = cv.function(train.hog,5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.function(train.lbp, 5)
cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
xgboost.model = train.xgboost(train.hog)
xgboost.model = train.xgboost(train.hog)
xgboost.pre = test.xgboost(xgboost.model,test.hog)
table(xgboost.pre, test.hog$y)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.lbp =cv.function(train.lbp, 5)
cv.error.hog = cv.function(train.hog,5)
View(cv.error.lbp)
View(cv.error.hog)
View(cv.error.lbp)
print (cv.error.lbp)
print(cv.error.hog)
print (cv.error.lbp)
c=system.time(bp <- train.bp(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
d=system.time(rf <- train.rf(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
e=system.time(svm <- train.svm(lbpdata))
f=system.time(logistic <- train.log(lbpdata))
time=list(baseline=a,gbm=b,bp=c,rf=d,svm=e,logistic=f,vote=NA)
time=list(gbm=b,bp=c,rf=d,svm=e,logistic=f,vote=NA)
time=list(bp=c,rf=d,svm=e,logistic=f,vote=NA)
cv.error
time
cv.error.lbp
cv.error.hog
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
write(time,"time.csv")
time=list(bp=c,rf=d,svm=e,logistic=f,vote=NA)
write(time,"time.csv")
print(time)
View(hogdata)
View(hogdata)
g = system.time(xgboost = train.xgboost(lbpdata))
g = system.time(xgboost = train.xgboost(lbpdata))
View(lbpdata)
g = system.time(xgboost = train.xgboost(lbpdata))
g = system.time(xgboost <- train.xgboost(lbpdata))
time=list(bp=c,rf=d,svm=e,logistic=f,xgboost = g)
time
cv.error.lbp =cv.function(lbpdata,5)
cv.error.lbp =cv.function(lbpdata,5)
cv.error.hog = cv.function(hogdata,5)
print (cv.error.lbp)
print(cv.error.hog)
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
source("../lib/cross_validation.R")
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(lbpdata,5)
source("../lib/cross_validation.R")
cv.error.lbp =cv.function(lbpdata,5)
cv.error.lbp =cv.function(lbpdata,5)
cv.error.hog = cv.function(hogdata,5)
source("../lib/cross_validation.R")
write.csv(cv.error.lbp,"cv.error.lbp.csv")
write.csv(cv.error.hog,"cv.error.hog.csv")
